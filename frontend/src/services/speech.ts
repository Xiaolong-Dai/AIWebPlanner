import { useApiConfigStore } from '../store/apiConfigStore';
import CryptoJS from 'crypto-js';

/**
 * ç§‘å¤§è®¯é£è¯­éŸ³è¯†åˆ«æœåŠ¡
 * ä½¿ç”¨ WebSocket å®æ—¶è¯­éŸ³è¯†åˆ«
 */

export interface SpeechRecognitionResult {
  text: string;
  confidence: number;
  is_final: boolean;
}

export interface SpeechConfig {
  onResult: (result: SpeechRecognitionResult) => void;
  onError: (error: Error) => void;
  onEnd: () => void;
  language?: 'zh_cn' | 'en_us';
  accent?: 'mandarin' | 'cantonese';
}

/**
 * è·å–ç§‘å¤§è®¯é£é…ç½®
 */
const getXfeiConfig = () => {
  const { config } = useApiConfigStore.getState();
  const appId = config.xfei_app_id || import.meta.env.VITE_XFEI_APP_ID;
  const apiKey = config.xfei_api_key || import.meta.env.VITE_XFEI_API_KEY;
  const apiSecret = config.xfei_api_secret || import.meta.env.VITE_XFEI_API_SECRET;

  if (!appId || !apiKey || !apiSecret) {
    throw new Error('ç§‘å¤§è®¯é£ API æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢é…ç½®');
  }

  return { appId, apiKey, apiSecret };
};

/**
 * ç”Ÿæˆ WebSocket è®¤è¯ URL
 */
const getWebSocketUrl = (apiKey: string, apiSecret: string): string => {
  const url = 'wss://iat-api.xfyun.cn/v2/iat';
  const host = 'iat-api.xfyun.cn';
  const date = new Date().toUTCString();
  const algorithm = 'hmac-sha256';
  const headers = 'host date request-line';

  const signatureOrigin = `host: ${host}\ndate: ${date}\nGET /v2/iat HTTP/1.1`;
  const signatureSha = CryptoJS.HmacSHA256(signatureOrigin, apiSecret);
  const signature = CryptoJS.enc.Base64.stringify(signatureSha);

  const authorizationOrigin = `api_key="${apiKey}", algorithm="${algorithm}", headers="${headers}", signature="${signature}"`;
  const authorization = btoa(authorizationOrigin);

  return `${url}?authorization=${authorization}&date=${encodeURIComponent(date)}&host=${host}`;
};

/**
 * è¯­éŸ³è¯†åˆ«ç±»
 */
export class SpeechRecognizer {
  private ws: WebSocket | null = null;
  private config: SpeechConfig;
  private appId: string;
  private apiKey: string;
  private apiSecret: string;
  private isRecording = false;
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private processor: ScriptProcessorNode | null = null;
  private sampleRate = 0; // å®é™…é‡‡æ ·ç‡

  constructor(config: SpeechConfig) {
    this.config = config;
    const xfeiConfig = getXfeiConfig();
    this.appId = xfeiConfig.appId;
    this.apiKey = xfeiConfig.apiKey;
    this.apiSecret = xfeiConfig.apiSecret;
  }

  /**
   * å¼€å§‹å½•éŸ³å’Œè¯†åˆ«
   */
  async start(): Promise<void> {
    if (this.isRecording) {
      throw new Error('å·²ç»åœ¨å½•éŸ³ä¸­');
    }

    try {
      // è·å–éº¦å…‹é£æƒé™
      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      this.sampleRate = this.audioContext.sampleRate;

      console.log('ğŸ¤ [è¯­éŸ³è¯†åˆ«] AudioContext é‡‡æ ·ç‡:', this.sampleRate, 'Hz');
      console.log('ğŸ¤ [è¯­éŸ³è¯†åˆ«] ç›®æ ‡é‡‡æ ·ç‡: 16000 Hz');

      const source = this.audioContext.createMediaStreamSource(this.mediaStream);

      // åˆ›å»ºå¤„ç†å™¨
      this.processor = this.audioContext.createScriptProcessor(4096, 1, 1);

      // è¿æ¥ WebSocket
      await this.connectWebSocket();

      // å¤„ç†éŸ³é¢‘æ•°æ®
      this.processor.onaudioprocess = (e) => {
        if (!this.isRecording || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
          return;
        }

        const inputData = e.inputBuffer.getChannelData(0);
        const pcmData = this.convertToPCM(inputData);
        const base64Data = this.arrayBufferToBase64(pcmData);

        // å‘é€éŸ³é¢‘æ•°æ®
        this.ws.send(
          JSON.stringify({
            data: {
              status: 1, // 0: ç¬¬ä¸€å¸§, 1: ä¸­é—´å¸§, 2: æœ€åä¸€å¸§
              format: 'audio/L16;rate=16000',
              encoding: 'raw',
              audio: base64Data,
            },
          })
        );
      };

      source.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      this.isRecording = true;
    } catch (error) {
      console.error('âŒ [è¯­éŸ³è¯†åˆ«] å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
      this.config.onError(error as Error);
      throw error;
    }
  }

  /**
   * åœæ­¢å½•éŸ³å’Œè¯†åˆ«
   */
  stop(): void {
    if (!this.isRecording) {
      return;
    }

    this.isRecording = false;

    // å‘é€ç»“æŸå¸§
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(
        JSON.stringify({
          data: {
            status: 2, // æœ€åä¸€å¸§
            format: 'audio/L16;rate=16000',
            encoding: 'raw',
            audio: '',
          },
        })
      );
    }

    // æ¸…ç†èµ„æº
    if (this.processor) {
      this.processor.disconnect();
      this.processor = null;
    }

    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach((track) => track.stop());
      this.mediaStream = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
  }

  /**
   * è¿æ¥ WebSocket
   */
  private connectWebSocket(): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        const wsUrl = getWebSocketUrl(this.apiKey, this.apiSecret);
        this.ws = new WebSocket(wsUrl);

        this.ws.onopen = () => {
          console.log('âœ… [è¯­éŸ³è¯†åˆ«] WebSocket è¿æ¥æˆåŠŸ');

          // å‘é€å¼€å§‹å¸§
          const params = {
            common: {
              app_id: this.appId,
            },
            business: {
              language: this.config.language || 'zh_cn',
              domain: 'iat',
              accent: this.config.accent || 'mandarin',
              vad_eos: 2000, // ä¼˜åŒ–ï¼šä» 5000ms é™ä½åˆ° 2000msï¼Œæ›´å¿«å“åº”
              dwa: 'wpgs', // åŠ¨æ€ä¿®æ­£
              pd: 'travel', // é¢†åŸŸï¼šæ—…æ¸¸
              ptt: 1, // å¼€å¯æ ‡ç‚¹
              nunum: 1, // å°†æ•°å­—è½¬ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
            },
            data: {
              status: 0,
              format: 'audio/L16;rate=16000',
              encoding: 'raw',
              audio: '',
            },
          };

          console.log('ğŸ“¤ [è¯­éŸ³è¯†åˆ«] å‘é€é…ç½®å‚æ•°:', params.business);
          this.ws!.send(JSON.stringify(params));
          resolve();
        };

        this.ws.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);

            if (data.code !== 0) {
              console.error('âŒ [è¯­éŸ³è¯†åˆ«] è¯†åˆ«é”™è¯¯:', data.message, 'é”™è¯¯ç :', data.code);
              this.config.onError(new Error(`è¯†åˆ«é”™è¯¯: ${data.message}`));
              return;
            }

            if (data.data && data.data.result) {
              const result = data.data.result;
              const text = result.ws
                .map((w: any) => w.cw.map((c: any) => c.w).join(''))
                .join('');

              // è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
              const confidences = result.ws.flatMap((w: any) =>
                w.cw.map((c: any) => c.wp || 0)
              );
              const avgConfidence = confidences.length > 0
                ? confidences.reduce((a: number, b: number) => a + b, 0) / confidences.length
                : 0;

              console.log('ğŸ“ [è¯­éŸ³è¯†åˆ«] è¯†åˆ«ç»“æœ:', {
                text,
                confidence: avgConfidence,
                is_final: data.data.status === 2,
                raw_result: result
              });

              this.config.onResult({
                text,
                confidence: avgConfidence,
                is_final: data.data.status === 2,
              });
            }

            if (data.data && data.data.status === 2) {
              console.log('ğŸ [è¯­éŸ³è¯†åˆ«] è¯†åˆ«å®Œæˆ');
              this.config.onEnd();
            }
          } catch (error) {
            console.error('âŒ [è¯­éŸ³è¯†åˆ«] è§£æè¯†åˆ«ç»“æœå¤±è´¥:', error);
            this.config.onError(error as Error);
          }
        };

        this.ws.onerror = (error) => {
          console.error('WebSocket é”™è¯¯:', error);
          this.config.onError(new Error('è¯­éŸ³è¯†åˆ«è¿æ¥å¤±è´¥'));
          reject(error);
        };

        this.ws.onclose = () => {
          this.config.onEnd();
        };
      } catch (error) {
        reject(error);
      }
    });
  }

  /**
   * è½¬æ¢ä¸º PCM æ ¼å¼å¹¶é‡é‡‡æ ·åˆ° 16000Hz
   */
  private convertToPCM(input: Float32Array): ArrayBuffer {
    const targetSampleRate = 16000;
    const sourceSampleRate = this.sampleRate;

    // å¦‚æœé‡‡æ ·ç‡ä¸åŒï¼Œéœ€è¦é‡é‡‡æ ·
    let resampledData: Float32Array;
    if (sourceSampleRate !== targetSampleRate) {
      const sampleRateRatio = sourceSampleRate / targetSampleRate;
      const newLength = Math.round(input.length / sampleRateRatio);
      resampledData = new Float32Array(newLength);

      for (let i = 0; i < newLength; i++) {
        const srcIndex = i * sampleRateRatio;
        const srcIndexInt = Math.floor(srcIndex);
        const srcIndexFrac = srcIndex - srcIndexInt;

        // çº¿æ€§æ’å€¼
        if (srcIndexInt + 1 < input.length) {
          resampledData[i] = input[srcIndexInt] * (1 - srcIndexFrac) +
                            input[srcIndexInt + 1] * srcIndexFrac;
        } else {
          resampledData[i] = input[srcIndexInt];
        }
      }
    } else {
      resampledData = input;
    }

    // è½¬æ¢ä¸º 16 ä½ PCM
    const output = new Int16Array(resampledData.length);
    for (let i = 0; i < resampledData.length; i++) {
      const s = Math.max(-1, Math.min(1, resampledData[i]));
      output[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }

    return output.buffer;
  }

  /**
   * ArrayBuffer è½¬ Base64
   */
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

/**
 * ç®€åŒ–çš„è¯­éŸ³è¯†åˆ«å‡½æ•°
 */
export const startSpeechRecognition = (
  onResult: (text: string) => void,
  onError?: (error: Error) => void
): SpeechRecognizer => {
  let fullText = '';
  let currentSentence = ''; // å½“å‰å¥å­çš„ä¸´æ—¶ç»“æœ

  const recognizer = new SpeechRecognizer({
    onResult: (result) => {
      console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ:', {
        text: result.text,
        is_final: result.is_final,
        confidence: result.confidence
      });

      if (result.text) {
        if (result.is_final) {
          // æœ€ç»ˆç»“æœï¼šå°†å½“å‰å¥å­å’Œæœ€ç»ˆç»“æœï¼ˆé€šå¸¸æ˜¯æ ‡ç‚¹ï¼‰è¿½åŠ åˆ°å®Œæ•´æ–‡æœ¬
          fullText += currentSentence + result.text;
          currentSentence = ''; // æ¸…ç©ºå½“å‰å¥å­
          console.log('âœ… æœ€ç»ˆè¯†åˆ«æ–‡æœ¬ï¼ˆç´¯ç§¯ï¼‰:', fullText);
          console.log('   å½“å‰å¥å­:', currentSentence, '+ æœ€ç»ˆç»“æœ:', result.text);

          // å›è°ƒå®Œæ•´æ–‡æœ¬
          onResult(fullText);
        } else {
          // ä¸´æ—¶ç»“æœï¼šæ›´æ–°å½“å‰å¥å­
          currentSentence = result.text;
          console.log('ğŸ“ ä¸´æ—¶è¯†åˆ«æ–‡æœ¬:', currentSentence);

          // å›è°ƒï¼šå®Œæ•´æ–‡æœ¬ + å½“å‰ä¸´æ—¶å¥å­
          onResult(fullText + currentSentence);
        }
      }
    },
    onError: (error) => {
      console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
      if (onError) {
        onError(error);
      }
    },
    onEnd: () => {
      console.log('ğŸ è¯­éŸ³è¯†åˆ«ç»“æŸ');
      console.log('   å®Œæ•´æ–‡æœ¬:', fullText);
      console.log('   å½“å‰å¥å­:', currentSentence);

      // å¦‚æœè¿˜æœ‰æœªå®Œæˆçš„å¥å­ï¼Œä¹ŸåŠ å…¥åˆ°å®Œæ•´æ–‡æœ¬
      if (currentSentence) {
        fullText += currentSentence;
      }

      if (fullText) {
        onResult(fullText);
      }
    },
  });

  // ä¸åœ¨è¿™é‡Œè‡ªåŠ¨å¯åŠ¨,è®©è°ƒç”¨è€…æ§åˆ¶
  return recognizer;
};

